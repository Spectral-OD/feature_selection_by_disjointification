{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee51ee-aeb8-4e2f-8436-c9ff42ca7cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import scienceplots\n",
    "import sklearn.metrics\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "plt.style.use(['science', 'notebook'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if 'labels_df' not in locals() or 'features_df' not in locals():\n",
    "    labels_file_path = Path(r\"c:/data/sampleinfo_SCANB_t.csv\")\n",
    "    features_file_path = Path(r\"c:\\data\\SCANB.csv\")\n",
    "\n",
    "    labels_df = pd.read_csv(labels_file_path)\n",
    "    features_df = pd.read_csv(features_file_path)\n",
    "    \n",
    "def wilcoxon_p_value(x,y):\n",
    "    w_test = wilcoxon(x,y)\n",
    "    return w_test.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1957ab8-0095-4ae2-8121-4389a36f3f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionTest:\n",
    "\n",
    "    def __init__(self, features_file_path=None, labels_file_path=None, labels_df=None, features_df=None, select_num_features=None, select_num_instances=None, selected_labels=None, test_size=0.2, lin_regressor_label=\"Lympho\" ,log_regressor_label=\"ER\"):\n",
    "        \n",
    "        self.features_file_path=features_file_path\n",
    "        self.labels_file_path=labels_file_path\n",
    "        self.labels_df=labels_df\n",
    "        self.features_df=features_df\n",
    "        self.select_num_features=select_num_features\n",
    "        self.select_num_instances=select_num_instances\n",
    "        self.selected_labels=selected_labels\n",
    "        self.features_and_labels_df = None\n",
    "        self.shape = None\n",
    "        self.test_size = test_size\n",
    "        self.log_regressor_label = log_regressor_label\n",
    "        self.lin_regressor_label = lin_regressor_label\n",
    "        \n",
    "        self.set_inputs()\n",
    "        \n",
    "    def set_inputs(self):\n",
    "        \n",
    "        self.set_dfs()\n",
    "        self.set_wrapped_attributes()\n",
    "        self.set_corr_matrices()\n",
    "        self.set_feature_lists()\n",
    "    \n",
    "    def set_dfs(self):\n",
    "        if self.labels_df is None: \n",
    "            self.labels_df = pd.read_csv(self.labels_file_path)\n",
    "            \n",
    "                \n",
    "        if self.features_df is None:\n",
    "            self.features_df = pd.read_csv(self.features_file_path)\n",
    "        \n",
    "        self.labels_df.drop([\"Unnamed: 0\"], errors='ignore', inplace=True, axis=1)\n",
    "        self.features_df.drop([\"Unnamed: 0\"], errors='ignore', inplace=True, axis=1)\n",
    "            \n",
    "        if self.select_num_instances is not None:\n",
    "            instances_to_keep = range(self.select_num_instances)\n",
    "            self.labels_df = self.labels_df.iloc[instances_to_keep]\n",
    "            self.features_df = self.features_df.iloc[instances_to_keep]\n",
    "\n",
    "        if self.select_num_features is not None:\n",
    "            features_to_keep = range(self.select_num_features)\n",
    "            # feature_names_to_keep = features_df.columns[features_to_keep]\n",
    "            self.features_df = self.features_df.iloc[:,features_to_keep]\n",
    "            \n",
    "        if self.selected_labels is not None:\n",
    "            self.labels_df = self.labels_df[self.selected_labels]\n",
    "            \n",
    "        self.features_and_labels_df = self.features_df.join(self.labels_df)\n",
    "        self.num_features = self.features_df.shape[1]\n",
    "        self.num_labels = self.features_df.shape[0]\n",
    "        self.num_instances = self.features_df.shape[0]\n",
    "        \n",
    "    def remove_unnamed_cols():\n",
    "        self.features_df.drop\n",
    "        \n",
    "    def set_wrapped_attributes(self):\n",
    "        self.set_shape()\n",
    "        self.set_columns()\n",
    "    \n",
    "    def set_shape(self):\n",
    "        out_dict = {\"features\":self.features_df.shape, \"labels\":self.labels_df.shape}\n",
    "        self.shape = pd.Series(out_dict)\n",
    "\n",
    "    def set_columns(self):\n",
    "        out_dict = {\"features\":self.features_df.columns, \"labels\":self.labels_df.columns}\n",
    "        self.columns = pd.Series(out_dict)\n",
    "        \n",
    "    def head(self, n=5):\n",
    "        return self.features_and_labels_df.head(n)\n",
    "    \n",
    "    def tail(self, n=5):\n",
    "        return self.features_and_labels_df.tail(n)\n",
    "    \n",
    "    def run_linear_regression(self, selected_features=None):\n",
    "        self.linear_regressor = LinearRegression()\n",
    "        y = self.labels_df[self.lin_regressor_label]\n",
    "        if self.features_already_selected_lin is None:\n",
    "            x = self.features_df\n",
    "        else:\n",
    "            x = self.features_df[self.features_already_selected_lin]\n",
    "        if selected_features is not None:\n",
    "            x = x[selected_features]\n",
    "\n",
    "        self.x_train_lin, self.x_test_lin, self.y_train_lin, self.y_test_lin = train_test_split(x, y, test_size=self.test_size, random_state=47)\n",
    "        self.linear_regressor.fit(self.x_train_lin, self.y_train_lin)\n",
    "        self.y_pred_lin = self.linear_regressor.predict(self.x_test_lin)\n",
    "        self.lin_score = self.linear_regressor.score(self.x_test_lin, self.y_test_lin)\n",
    "\n",
    "    def run_log_regression(self, selected_features=None):\n",
    "        self.logistic_regressor = LogisticRegression()\n",
    "        y = self.labels_df[self.log_regressor_label]\n",
    "        if self.features_already_selected_log is None:\n",
    "            x = self.features_df\n",
    "        else:\n",
    "            x = self.features_df[self.features_already_selected_log]\n",
    "        \n",
    "        if selected_features is not None:\n",
    "            x = x[selected_features]\n",
    "            \n",
    "        self.x_train_log, self.x_test_log, self.y_train_log, self.y_test_log = train_test_split(x, y, test_size=self.test_size, random_state=47)\n",
    "        self.logistic_regressor.fit(self.x_train_log, self.y_train_log)\n",
    "        self.y_pred_log = self.logistic_regressor.predict(self.x_test_log)\n",
    "        self.log_score = self.logistic_regressor.score(self.x_test_log, self.y_test_log)\n",
    "        self.log_confusion_matrix = sklearn.metrics.confusion_matrix(y_true = self.y_test_log, y_pred=self.y_pred_log, normalize='all')\n",
    "        \n",
    "    def show_linear_regressor(self, figsize=(6,6), ax=None):\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(1,1, figsize=figsize)\n",
    "        sns.scatterplot(x=self.y_pred_lin, y=self.y_test_lin, ax=ax)\n",
    "        ax.set(title=f\"linear regressor using dataset of total \\n {self.x_train_lin.shape} train and {self.x_test_lin.shape} test. \\nScore: {self.lin_score:.2f}\", xlabel=\"y_test\", ylabel=\"y_pred\")\n",
    "        ax.grid(\"minor\")\n",
    "    \n",
    "    def show_log_regressor(self, figsize=(6,6), ax=None, cmap=\"viridis\"):\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(1,1, figsize=figsize)\n",
    "        sklearn.metrics.ConfusionMatrixDisplay.from_predictions(self.y_test_log, self.y_pred_log, ax=ax, cmap=cmap)\n",
    "        ax.set(title=f\"log regressor using dataset of total \\n {self.x_train_log.shape} train and {self.x_test_log.shape} test. \\nScore: {self.log_score:.2f}\")\n",
    "        \n",
    "    def show(self, fig=None, figsize=(12,6)):\n",
    "        if fig is None:\n",
    "            fig, axs =plt.subplots(1,2,figsize=figsize)\n",
    "        ax = axs.flatten()[0]\n",
    "        ax.grid(\"minor\")\n",
    "        self.show_linear_regressor(ax=ax, figsize=(figsize[0]//2,figsize[1]))\n",
    "        ax = axs.flatten()[1]\n",
    "        self.show_log_regressor(ax=ax, figsize=(figsize[0]//2,figsize[1]))\n",
    "            \n",
    "    def show_classification_report(self):\n",
    "        print(sklearn.metrics.classification_report(self.y_test_log, self.y_pred_log))\n",
    "        \n",
    "    def show_regression_report(self):\n",
    "        print(sklearn.metrics.reg)\n",
    "        \n",
    "    def set_corr_matrices(self):\n",
    "        self.correlation_matrix_lin = self.features_and_labels_df.drop(columns=self.log_regressor_label).corr().drop(self.lin_regressor_label)\n",
    "        self.correlation_matrix_log = self.features_and_labels_df.drop(columns=self.lin_regressor_label).corr(method=wilcoxon_p_value).drop(self.log_regressor_label)\n",
    "        self.correlation_ranking_lin = self.correlation_matrix_lin[self.lin_regressor_label].sort_values(ascending=False)\n",
    "        self.correlation_ranking_log = self.correlation_matrix_log[self.log_regressor_label].sort_values(ascending=False)\n",
    "    \n",
    "    def set_feature_lists(self):\n",
    "        self.features_already_selected_lin = []\n",
    "        self.features_already_selected_log = []\n",
    "        self.features_rejected_lin = []\n",
    "        self.features_rejected_log = []\n",
    "        self.features_not_yet_selected_lin = self.features_df.columns\n",
    "        self.features_not_yet_selected_log = self.features_df.columns\n",
    "        self.number_of_features_tested_lin = 0\n",
    "        self.number_of_features_tested_log = 0\n",
    "    \n",
    "    def run_iterative_feature_selection(self, mode, num_iterations=None, correlation_threshold=0.1, min_num_of_features=None, debug_print=False, alert_selection=False):\n",
    "        \n",
    "        if num_iterations is None:\n",
    "            num_iterations = self.num_features\n",
    "        \n",
    "        if mode == 'lin':\n",
    "            self.features_to_test_list = self.correlation_matrix_lin[self.lin_regressor_label].abs().sort_values(ascending=False).index\n",
    "        if mode == 'log':\n",
    "            self.features_to_test_list = self.correlation_matrix_log[self.log_regressor_label].abs().sort_values(ascending=False).index\n",
    "        if debug_print:\n",
    "            print(f\"features_to_test_list {self.features_to_test_list}\")\n",
    "\n",
    "        for iter in range(num_iterations):\n",
    "            \n",
    "            if debug_print:\n",
    "                print(f\"features to test list - {self.features_to_test_list}\")\n",
    "            if mode == 'lin' :\n",
    "                \n",
    "                self.candidate_feature = str(self.features_to_test_list[self.number_of_features_tested_lin])\n",
    "                self.features_already_selected = self.features_already_selected_lin\n",
    "            if mode == 'log' : \n",
    "                self.candidate_feature = str(self.features_to_test_list[self.number_of_features_tested_log])\n",
    "                self.features_already_selected = self.features_already_selected_log\n",
    "            \n",
    "            if debug_print:\n",
    "                print(f\"self.candidate_feature: {self.candidate_feature}\")\n",
    "                \n",
    "            if len(self.features_already_selected) == 0:\n",
    "                # self.features_already_selected.append(self.candidate_feature)\n",
    "                \n",
    "                if mode == 'lin' :\n",
    "                    self.features_already_selected_lin.append(self.candidate_feature)\n",
    "                if mode == 'log' : \n",
    "                    self.features_already_selected_log.append(self.candidate_feature)\n",
    "            ## Iterate\n",
    "            else:\n",
    "                if mode == 'lin':\n",
    "                    self.selected_feature_data = self.features_df[self.features_already_selected_lin]\n",
    "                if mode == 'log':\n",
    "                    self.selected_feature_data = self.features_df[self.features_already_selected_log]\n",
    "                \n",
    "                self.candidate_feature_data = self.features_df[[self.candidate_feature]]\n",
    "                \n",
    "\n",
    "                if debug_print:\n",
    "                    print(f\"self.features_already_selected_lin: {self.features_already_selected_lin}\")\n",
    "                    print(f\"candidate_feature_data: {self.candidate_feature_data}\")\n",
    "                    print(f\"selected_feature_data: {self.selected_feature_data}\")\n",
    "\n",
    "                # self.df_candidate_vs_existing = self.candidate_feature_data.join(self.selected_feature_data)\n",
    "                # # self.df_candidate_vs_existing = pd.concat([self.candidate_feature_data,self.selected_feature_data])\n",
    "                self.candidate_and_selected_features = list(self.features_already_selected) + [self.candidate_feature]\n",
    "                self.df_candidate_vs_existing = self.features_df[self.candidate_and_selected_features]\n",
    "                \n",
    "                if mode == 'lin':\n",
    "                    self.test_corr_matrix = self.df_candidate_vs_existing.corr()\n",
    "                if mode == 'log':\n",
    "                    self.test_corr_matrix = self.df_candidate_vs_existing.corr(method=wilcoxon_p_value)\n",
    "                \n",
    "                self.correlation_with_prevs_features = self.test_corr_matrix[self.candidate_feature].drop(self.candidate_feature)\n",
    "\n",
    "                if debug_print:\n",
    "                    print(f\"correaltion with prevs: {self.correlation_with_prevs_features}\")\n",
    "\n",
    "                if self.correlation_with_prevs_features.abs().max() <= correlation_threshold:\n",
    "                    if alert_selection:\n",
    "                        print(f\"found a new feature to use!\")\n",
    "                \n",
    "            # advance index\n",
    "            if mode == 'lin':\n",
    "                self.features_already_selected_lin.append(self.candidate_feature)\n",
    "                self.number_of_features_tested_lin = self.number_of_features_tested_lin + 1\n",
    "            if mode == 'log':\n",
    "                self.features_already_selected_log.append(self.candidate_feature)\n",
    "                self.number_of_features_tested_log = self.number_of_features_tested_log + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb27955b-9386-4af8-9476-80e7387fb7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : posible check on indexing issue\n",
    "\n",
    "select_num_features = 100\n",
    "select_num_instances = 3000\n",
    "selected_labels = [\"ER\", \"Lympho\"]\n",
    "correlation_threshold = 0.2\n",
    "alert_selection = True\n",
    "debug_print = False\n",
    "test = FeatureSelectionTest(features_file_path=None, labels_file_path=None, features_df=features_df, labels_df=labels_df, select_num_features=select_num_features, select_num_instances=select_num_instances, selected_labels=selected_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2de50e2-9632-432e-9def-418d53e3e634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a new feature to use!\n",
      "found a new feature to use!\n",
      "found a new feature to use!\n"
     ]
    }
   ],
   "source": [
    "test.run_iterative_feature_selection(mode='lin', num_iterations=5, correlation_threshold = correlation_threshold, alert_selection=alert_selection, debug_print=debug_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54af087-a42d-4552-9fc4-93083125248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.run_linear_regression()\n",
    "test.run_log_regression()\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9eb3c5-b8e2-45f1-9a0a-8b8952aac4b9",
   "metadata": {},
   "source": [
    "## Meeting 24/05\n",
    "\n",
    "- Disjointification should be done - \n",
    "- RF + Lasso benchmark\n",
    "- Let's try OOB solutions - genetic?\n",
    "- Propose other methods ? \n",
    "- RFE\n",
    "- Can test another method that'll reduce to 500 and then do the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13137dd-1865-4368-9e92-f58eb18f4b38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
